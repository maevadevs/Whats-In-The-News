{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classifications For AllTheNews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pre-splitted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.24.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.1) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.1) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.1) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.1) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'scikit-learn==0.24.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from azureml.core import Workspace, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 3000\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/X_resampled.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '546d9c91-7fcf-4547-836c-10b640e06628'\n",
    "resource_group = 'NSSCapstoneProject'\n",
    "workspace_name = 'AllTheNews21'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='X_resampled')\n",
    "dataset.download(target_path='.', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        christina el moussa ant anstead unique morning...\n",
       "1        toyota motor president donald trump latest mov...\n",
       "2        market week property flatiron district park sl...\n",
       "3        detroit toyota motor shift production tacoma m...\n",
       "4        reuters drugmaker pfizer inc signed deal germa...\n",
       "                               ...                        \n",
       "53755    reuters goldman sachs group inc thursday joine...\n",
       "53756    reuters inc share surged friday pushing stock ...\n",
       "53757    new york reuters future employee training invo...\n",
       "53758    new york reuters investor pulled billion stock...\n",
       "53759    new york reuters guggenheim partner global chi...\n",
       "Name: processed_contents, Length: 53760, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled = pd.read_csv(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/X_resampled.csv\")\n",
    "X_resampled = X_resampled.squeeze()\n",
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/X_test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '546d9c91-7fcf-4547-836c-10b640e06628'\n",
    "resource_group = 'NSSCapstoneProject'\n",
    "workspace_name = 'AllTheNews21'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='X_test')\n",
    "dataset.download(target_path='.', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        couple suing fertility clinic trumbell connect...\n",
       "1        ivanka trump led delegation winter olympics cl...\n",
       "2        san francisco reuters federal reserve official...\n",
       "3        shopping guide small luxury sometimes essentia...\n",
       "4        good appetite unfussy sausage bake rounded par...\n",
       "                               ...                        \n",
       "12942    seller high hope reality current market deflat...\n",
       "12943    getaway look ahead new airport security proced...\n",
       "12944    insight enterprise inc insight enterprise repo...\n",
       "12945    cnn former vice president joe biden brought ol...\n",
       "12946    president donald trump democratic sherrod brow...\n",
       "Name: processed_contents, Length: 12947, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/X_test.csv\")\n",
    "X_test = X_test.squeeze()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/y_resampled.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '546d9c91-7fcf-4547-836c-10b640e06628'\n",
    "resource_group = 'NSSCapstoneProject'\n",
    "workspace_name = 'AllTheNews21'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='y_resampled')\n",
    "dataset.download(target_path='.', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        14\n",
       "1         1\n",
       "2        14\n",
       "3         1\n",
       "4         8\n",
       "         ..\n",
       "53755    19\n",
       "53756    19\n",
       "53757    19\n",
       "53758    19\n",
       "53759    19\n",
       "Name: category_target, Length: 53760, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled = pd.read_csv(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/y_resampled.csv\", header=None, names=[\"category_target\"])\n",
    "y_resampled = y_resampled.squeeze()\n",
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/y_test.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '546d9c91-7fcf-4547-836c-10b640e06628'\n",
    "resource_group = 'NSSCapstoneProject'\n",
    "workspace_name = 'AllTheNews21'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='y_test')\n",
    "dataset.download(target_path='.', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10\n",
       "1        13\n",
       "2         2\n",
       "3        14\n",
       "4         6\n",
       "         ..\n",
       "12942    14\n",
       "12943    17\n",
       "12944    11\n",
       "12945    13\n",
       "12946    13\n",
       "Name: category_target, Length: 12947, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/nlpprocessor78/code/Users/maevadevs/y_test.csv\", header=None, names=[\"category_target\"])\n",
    "y_test = y_test.squeeze()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 500 TF-IDF Features on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     encoding=\"utf-8\",\n",
    "#     ngram_range=(1, 2),    # We are doing up to bigrams\n",
    "#     stop_words=None,       # We already cleaned the text earlier in pre-processing\n",
    "#     lowercase=False,       # We already cleaned the text earlier in pre-processing\n",
    "#     max_features = 500,\n",
    "#     norm = \"l2\",\n",
    "#     sublinear_tf = True\n",
    "# )\n",
    "\n",
    "# # Store the vectorized features and labels of the training and testing data\n",
    "# # We can pass these to various ML algorithms later for comparing classification performance\n",
    "# features_train = tfidf.fit_transform(X_resampled).toarray()\n",
    "# labels_train = y_resampled\n",
    "\n",
    "# # Only transform on the test data\n",
    "# features_test = tfidf.transform(X_test).toarray()\n",
    "# labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Plain SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Initialize the model\n",
    "# model_svc = SVC()\n",
    "\n",
    "# # Fit the model\n",
    "# model_svc.fit(features_train, labels_train)\n",
    "\n",
    "# # Predict on the test data\n",
    "# labels_pred = model_svc.predict(features_test)\n",
    "# display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# accuracy = accuracy_score(labels_test, labels_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classification Report\n",
    "# report = classification_report(labels_test, labels_pred)\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print Confusion Matrix\n",
    "# pd.DataFrame(confusion_matrix(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 5000 TF-IDF Features on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     encoding=\"utf-8\",\n",
    "#     ngram_range=(1, 2),    # We are doing up to bigrams\n",
    "#     stop_words=None,       # We already cleaned the text earlier in pre-processing\n",
    "#     lowercase=False,       # We already cleaned the text earlier in pre-processing\n",
    "#     max_features = 5000,\n",
    "#     norm = \"l2\",\n",
    "#     sublinear_tf = True\n",
    "# )\n",
    "\n",
    "# # Store the vectorized features and labels of the training and testing data\n",
    "# # We can pass these to various ML algorithms later for comparing classification performance\n",
    "# features_train = tfidf.fit_transform(X_resampled).toarray()\n",
    "# labels_train = y_resampled\n",
    "\n",
    "# # Only transform on the test data\n",
    "# features_test = tfidf.transform(X_test).toarray()\n",
    "# labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Plain SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Initialize the model\n",
    "# model_svc = SVC()\n",
    "\n",
    "# # Fit the model\n",
    "# model_svc.fit(features_train, labels_train)\n",
    "\n",
    "# # Predict on the test data\n",
    "# labels_pred = model_svc.predict(features_test)\n",
    "# display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# accuracy = accuracy_score(labels_test, labels_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classification Report\n",
    "# report = classification_report(labels_test, labels_pred)\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print Confusion Matrix\n",
    "# pd.DataFrame(confusion_matrix(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unable. The Kernel Dies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     encoding=\"utf-8\",\n",
    "#     ngram_range=(1, 2),    # We are doing up to bigrams\n",
    "#     stop_words=None,       # We already cleaned the text earlier in pre-processing\n",
    "#     lowercase=False,       # We already cleaned the text earlier in pre-processing\n",
    "#     max_features = 20000,\n",
    "#     norm = \"l2\",\n",
    "#     sublinear_tf = True\n",
    "# )\n",
    "\n",
    "# # Store the vectorized features and labels of the training and testing data\n",
    "# # We can pass these to various ML algorithms later for comparing classification performance\n",
    "# features_train = tfidf.fit_transform(X_resampled).toarray()\n",
    "# labels_train = y_resampled\n",
    "\n",
    "# # Only transform on the test data\n",
    "# features_test = tfidf.transform(X_test).toarray()\n",
    "# labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Plain SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Initialize the model\n",
    "# model_svc = SVC()\n",
    "\n",
    "# # Fit the model\n",
    "# model_svc.fit(features_train, labels_train)\n",
    "\n",
    "# # Predict on the test data\n",
    "# labels_pred = model_svc.predict(features_test)\n",
    "# display(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# accuracy = accuracy_score(labels_test, labels_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classification Report\n",
    "# report = classification_report(labels_test, labels_pred)\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print Confusion Matrix\n",
    "# pd.DataFrame(confusion_matrix(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, test cross-validations**\n",
    "\n",
    "## Using 5000 TF-IDF Features on CV LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "tfidf = TfidfVectorizer(\n",
    "    encoding=\"utf-8\",\n",
    "    ngram_range=(1, 2),    # We are doing up to bigrams\n",
    "    stop_words=None,       # We already cleaned the text earlier in pre-processing\n",
    "    lowercase=False,       # We already cleaned the text earlier in pre-processing\n",
    "    max_features = 5000,\n",
    "    norm = \"l2\",\n",
    "    sublinear_tf = True\n",
    ")\n",
    "\n",
    "# Store the vectorized features and labels of the training and testing data\n",
    "# We can pass these to various ML algorithms later for comparing classification performance\n",
    "features_train = tfidf.fit_transform(X_resampled).toarray()\n",
    "labels_train = y_resampled\n",
    "\n",
    "# Only transform on the test data\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomSearchCV on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the grid\n",
    "param_grid = {\n",
    "    \"tol\": [0.0001, 0.0005, 0.0010, 0.5],\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    \"penalty\": [\"l2\", None],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"solver\": [\"newton-cg\", \"sag\", \"saga\", \"lbfgs\"],\n",
    "    \"max_iter\": [10000],\n",
    "    \"multi_class\": [\"ovr\", \"multinomial\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Cross-Validation With 3-Folds\n",
    "model_lr_rs_cv = RandomizedSearchCV(\n",
    "    estimator = LogisticRegression(), \n",
    "    param_distributions = param_grid, \n",
    "    cv = 3, \n",
    "    n_iter = 100,\n",
    "    verbose=4,\n",
    "    n_jobs=-1 # Use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit on the training set to get the best model\n",
    "# best_lr = model_lr_rs_cv.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Result from RandomSearchCV are:\n",
    "\n",
    "```\n",
    "{'tol': 0.001,\n",
    " 'solver': 'lbfgs',\n",
    " 'penalty': 'l2',\n",
    " 'multi_class': 'multinomial',\n",
    " 'max_iter': 10000,\n",
    " 'fit_intercept': True,\n",
    " 'C': 1}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on LR CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = best_lr.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Train and Export This LR CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.6.2)\r\n",
      "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\r\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (7.1.2)\r\n",
      "Requirement already satisfied: regex in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2021.4.4)\r\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.60.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For pre-processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing function, which will be used by the TFIDF Vectorizer\n",
    "def process_text(text):\n",
    "    \"\"\"Preprocess a given text: \n",
    "        - Lowercase\n",
    "        - Tokenize\n",
    "        - Remove non-needed tokens\n",
    "        - Lemmatize\n",
    "        - Clean\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to lowercase, replace newlines with spaces, strip whitespaces\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Tokenize\n",
    "    word_tokens = word_tokenize(text)\n",
    "    # Convert to a numpy array\n",
    "    word_tokens = np.array(word_tokens)\n",
    "\n",
    "    # Keep only alphabetic characters\n",
    "    is_alpha = list(map(str.isalpha, word_tokens))\n",
    "    word_tokens = word_tokens[is_alpha]\n",
    "\n",
    "    # Remove stopwords\n",
    "    custom_stopwords = [\"said\", \"say\", \"says\"]\n",
    "    stop_words = set(stopwords.words(\"english\") + custom_stopwords)\n",
    "    is_not_stopword = list(map(lambda token: token not in stop_words, word_tokens))\n",
    "    word_tokens = word_tokens[is_not_stopword]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    vectorize_lemmatizer = np.vectorize(lemmatizer.lemmatize)\n",
    "    word_tokens = vectorize_lemmatizer(word_tokens)\n",
    "\n",
    "    # Convert into a setence form\n",
    "    sentence = \" \".join(word_tokens)\n",
    "\n",
    "    # Return final tokenized sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(lowercase=False, max_features=5000,\n",
       "                                 ngram_range=(1, 2),\n",
       "                                 preprocessor=<function process_text at 0x7fb397866598>,\n",
       "                                 strip_accents=True, sublinear_tf=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1, max_iter=10000,\n",
       "                                    multi_class='multinomial', tol=0.001))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "tfidf = TfidfVectorizer(\n",
    "    encoding=\"utf-8\",\n",
    "    strip_accents=True,\n",
    "    lowercase=False,             # Handled in process_text()\n",
    "    ngram_range=(1, 2),          # We are doing up to bigrams\n",
    "    preprocessor=process_text,   # Custom preprocessor\n",
    "    stop_words=None,             # Handled in process_text()\n",
    "    max_features = 5000,         # Best params we have found\n",
    "    norm = \"l2\",\n",
    "    sublinear_tf = True\n",
    ")\n",
    "\n",
    "# Logistic Regression with best params\n",
    "best_lr = LogisticRegression(\n",
    "    tol=0.001,\n",
    "    solver=\"lbfgs\",\n",
    "    penalty=\"l2\",\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=10000,\n",
    "    fit_intercept=True,\n",
    "    C=1\n",
    ")\n",
    "\n",
    "# Combine the Vectorizer and the Classifier\n",
    "pipe_tfidf_best_lr = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('classifier', best_lr),\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipe_tfidf_best_lr.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 16,  2, ..., 11, 18, 13])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = pipe_tfidf_best_lr.predict(X_test)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7411755619062331\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78       640\n",
      "           1       0.73      0.86      0.79       441\n",
      "           2       0.44      0.38      0.41       640\n",
      "           3       0.74      0.85      0.79       640\n",
      "           4       0.72      0.79      0.75       640\n",
      "           5       0.58      0.55      0.57       640\n",
      "           6       0.90      0.89      0.90       640\n",
      "           7       0.83      0.81      0.82       640\n",
      "           8       0.75      0.78      0.77       640\n",
      "           9       0.82      0.74      0.78       640\n",
      "          10       0.71      0.71      0.71       640\n",
      "          11       0.58      0.45      0.51       640\n",
      "          12       0.87      0.86      0.86       628\n",
      "          13       0.73      0.74      0.73       640\n",
      "          14       0.92      0.84      0.88       640\n",
      "          15       0.67      0.69      0.68       640\n",
      "          16       0.90      0.94      0.92       640\n",
      "          17       0.79      0.76      0.78       640\n",
      "          18       0.72      0.72      0.72       640\n",
      "          19       0.68      0.77      0.72       358\n",
      "          20       0.66      0.67      0.66       640\n",
      "\n",
      "    accuracy                           0.74     12947\n",
      "   macro avg       0.74      0.74      0.74     12947\n",
      "weighted avg       0.74      0.74      0.74     12947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>380</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>246</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>543</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>503</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>354</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>501</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>473</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>541</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>471</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>540</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>489</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n",
       "0   511    1    2    0    0    1    1    0    7   14   53    0    4    4    5   \n",
       "1     1  380   18    3    1    7    0    3    0    1    1    7    0    0    0   \n",
       "2     5   30  246   16   35   73    5    9    6    5    2   46    5   13    2   \n",
       "3     1    6   10  543   18    0    1    0    7    1    1    5    2    2    0   \n",
       "4     0    2   12   37  503   19    0    9    0    0    0   24    0    4    0   \n",
       "5     0    2   58    9   26  354    2   20    2    1    0   71    2   17    2   \n",
       "6     7    2    9    3    1    0  572    2   10    1   14    4    1    0    2   \n",
       "7     1    5   12    4   11   20    0  516   23    3    0   11    2    6    0   \n",
       "8    13    0    8    7    0    0   10   11  501    7   21    3   11    4    3   \n",
       "9    10    3   12    4    1    1    6    1   13  473   11    0    3   19    1   \n",
       "10   59    0    3    5    0    0    6    1   25    9  457    0    7    5    6   \n",
       "11    1   14   61   25   67   88    9   30    1    1    1  289    1   13    0   \n",
       "12    2    2    1    1    0    1    7    0   11    4    7    2  541    5    6   \n",
       "13    7    1   16   11    4    6    1    1   11    4    4    3    3  471    1   \n",
       "14   12    0    0    7    0    3    4    0    2    1   22    1    2    2  540   \n",
       "15   15   24   36   11    1    8    2    4   15    7    8   13    6    3    1   \n",
       "16    7    5    0    2    0    0    0    4    0    0    3    0    1    0    1   \n",
       "17   11   35    5    6    1    1    6    2    4    9   22    7    6    2    9   \n",
       "18   10    1    6   14    0    0    3    0   19   32   13    3    5   36    1   \n",
       "19    1    3   24    1    1    7    2    0    2    3    0    6   21    2    4   \n",
       "20    4    2   23   28   28   19    0   11    9    2    7    3    0   37    0   \n",
       "\n",
       "     15   16   17   18   19   20  \n",
       "0    14    2    4   15    0    2  \n",
       "1     6    6    3    0    2    2  \n",
       "2    43    2   17    6   41   33  \n",
       "3     4    1    4   12    2   20  \n",
       "4     0    0    0    1    2   27  \n",
       "5    13    2    0    0   32   27  \n",
       "6     3    0    5    3    1    0  \n",
       "7     3    8    1    1    2   11  \n",
       "8     8    2    3   15    1   12  \n",
       "9    37    2    9   25    7    2  \n",
       "10   12    8   14   13    1    9  \n",
       "11   15    0    0    1   13   10  \n",
       "12    7    5    3   12   11    0  \n",
       "13    5    2    1   42    3   43  \n",
       "14    4    0   37    2    1    0  \n",
       "15  444    2   17    4    8   11  \n",
       "16    4  602    2    5    0    4  \n",
       "17   17    2  489    3    0    3  \n",
       "18    9   12    5  460    2    9  \n",
       "19    3    1    1    0  276    0  \n",
       "20    8    7    2   20    2  428  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now, we export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file in the right directory\n",
    "pkl_filename = \"./MultinomialLogisticRegression-TFIDF5000-Best-RandomizedSearch3CV.pkl\"\n",
    "\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pipe_tfidf_best_lr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomSearchCV on Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "tfidf = TfidfVectorizer(\n",
    "    encoding=\"utf-8\",\n",
    "    ngram_range=(1, 2),    # We are doing up to bigrams\n",
    "    stop_words=None,       # We already cleaned the text earlier in pre-processing\n",
    "    lowercase=False,       # We already cleaned the text earlier in pre-processing\n",
    "    max_features = 5000,\n",
    "    norm = \"l2\",\n",
    "    sublinear_tf = True\n",
    ")\n",
    "\n",
    "# Store the vectorized features and labels of the training and testing data\n",
    "# We can pass these to various ML algorithms later for comparing classification performance\n",
    "features_train = tfidf.fit_transform(X_resampled).toarray()\n",
    "labels_train = y_resampled\n",
    "\n",
    "# Only transform on the test data\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the grid\n",
    "param_grid = {\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "    \"coef0\": [0.0, 0.5, 0.1],\n",
    "    \"cache_size\": [1000],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"verbose\":[True],\n",
    "    \"max_iter\": [10000],\n",
    "    \"decision_function_shape\": [\"ovo\", \"ovr\"],\n",
    "    \"break_ties\": [False],\n",
    "    \"random_state\": [777]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X should be a square kernel matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 585, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 205, in _safe_split\n    raise ValueError(\"X should be a square kernel matrix\")\nValueError: X should be a square kernel matrix\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-48dcc752a7c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel_svc_rs_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Predict on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X should be a square kernel matrix"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model_svc_rs_cv = RandomizedSearchCV(\n",
    "    estimator = SVC(), \n",
    "    param_distributions = param_grid, \n",
    "    cv = 2, \n",
    "    n_iter = 5,\n",
    "    verbose=4,\n",
    "    n_jobs=-1 # Use all cores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model_svc_rs_cv.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the test data\n",
    "labels_pred = model_svc_rs_cv.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit on the training set to get the best model\n",
    "best_svc = model_svc_rs_cv.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Them Together - Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify this based on best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a TF-IDF Vectorizer instance with some Hyper-Parameters\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     encoding=\"utf-8\",\n",
    "#     ngram_range=(1, 2),    # We are doing up to bigrams\n",
    "#     stop_words=None,       # We already cleaned the text earlier in pre-processing\n",
    "#     lowercase=False,       # We already cleaned the text earlier in pre-processing\n",
    "#     max_features = 20000,\n",
    "#     norm = \"l2\",\n",
    "#     sublinear_tf = True\n",
    "# )\n",
    "\n",
    "# # This could be another pipe\n",
    "# model_svc = SVC()\n",
    "\n",
    "# # Combine the Vectorizer and the Classifier\n",
    "# pipe = Pipeline([\n",
    "#     ('tfidf', tfidf),\n",
    "#     ('classifier', model_svc),\n",
    "# ])\n",
    "\n",
    "# # Fit the model: Apply cross-validation\n",
    "# pipe.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = make_pipeline(tfidf, model_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
