{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification -- BBC Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text Vectorization (from scikit-learn):\n",
    "  - TF-IDF Vectorizer\n",
    "- Classifiers (from scikit-learn):\n",
    "  - Random Forest\n",
    "  - Logistic Regression\n",
    "  - K-Nearest Neighbors\n",
    "  - Simple Decision Tree\n",
    "  - Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Set Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (1.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from wordcloud) (1.18.5)\r\n",
      "Requirement already satisfied: pillow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from wordcloud) (8.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from wordcloud) (3.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->wordcloud) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->wordcloud) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.4.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (4.14.3)\r\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from plotly) (1.16.0)\r\n",
      "Requirement already satisfied: retrying>=1.3.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from plotly) (1.3.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.6.2)\n",
      "Requirement already satisfied: regex in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.60.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1622511360804
    }
   },
   "outputs": [],
   "source": [
    "import os                              # Python default package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sqlalchemy import create_engine   # conda install -c anaconda sqlalchemy\n",
    "from wordcloud import WordCloud        # conda install -c conda-forge wordcloud\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Azure ML Specific\n",
    "from azureml.core import Workspace, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1622511361446
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.options.display.max_rows = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import Dataset\n",
    "\n",
    "In this notebook, we will be testing on `BBCArticles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1622511933140
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>titles</th>\n",
       "      <th>contents</th>\n",
       "      <th>content_lengths</th>\n",
       "      <th>processed_contents</th>\n",
       "      <th>category_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner...</td>\n",
       "      <td>2516</td>\n",
       "      <td>quarterly profits us media giant timewarner ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>2213</td>\n",
       "      <td>dollar hit highest level euro almost three mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuko...</td>\n",
       "      <td>1512</td>\n",
       "      <td>owners embattled russian oil giant yukos ask b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices fo...</td>\n",
       "      <td>2368</td>\n",
       "      <td>british airways blamed high fuel prices 40 dro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Share boost for feud-hit Reliance</td>\n",
       "      <td>The board of Indian conglomerate Reliance has ...</td>\n",
       "      <td>849</td>\n",
       "      <td>board indian conglomerate reliance agreed shar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                             titles  \\\n",
       "0  business  Ad sales boost Time Warner profit   \n",
       "1  business   Dollar gains on Greenspan speech   \n",
       "2  business  Yukos unit buyer faces loan claim   \n",
       "3  business  High fuel prices hit BA's profits   \n",
       "4  business  Share boost for feud-hit Reliance   \n",
       "\n",
       "                                            contents  content_lengths  \\\n",
       "0  Quarterly profits at US media giant TimeWarner...             2516   \n",
       "1  The dollar has hit its highest level against t...             2213   \n",
       "2  The owners of embattled Russian oil giant Yuko...             1512   \n",
       "3  British Airways has blamed high fuel prices fo...             2368   \n",
       "4  The board of Indian conglomerate Reliance has ...              849   \n",
       "\n",
       "                                  processed_contents  category_target  \n",
       "0  quarterly profits us media giant timewarner ju...                0  \n",
       "1  dollar hit highest level euro almost three mon...                0  \n",
       "2  owners embattled russian oil giant yukos ask b...                0  \n",
       "3  british airways blamed high fuel prices 40 dro...                0  \n",
       "4  board indian conglomerate reliance agreed shar...                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specific Azure ML for importing Datasets\n",
    "subscription_id = '546d9c91-7fcf-4547-836c-10b640e06628'\n",
    "resource_group = 'NSSCapstoneProject'\n",
    "workspace_name = 'BBCArticles'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='bbc-with-category-target')\n",
    "bbc = dataset.to_pandas_dataframe()\n",
    "\n",
    "display(bbc.shape)\n",
    "display(bbc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### How are these labels mapped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1622511976448
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('business', 0)\n",
      "('entertainment', 1)\n",
      "('politics', 2)\n",
      "('sport', 3)\n",
      "('tech', 4)\n"
     ]
    }
   ],
   "source": [
    "# Each pair of (category, category_target) records\n",
    "records = bbc[[\"category\", \"category_target\"]].to_records(index=False)\n",
    "\n",
    "# Checking the mapping of the new labels\n",
    "for pair in np.unique(np.array(records)):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Classification -- Ground Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Split data to Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1622512359838
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1622512369893
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Features and Target\n",
    "X = bbc[\"processed_contents\"]\n",
    "y = bbc[\"category_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1622512378197
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Perform train-test-split: 20% Test-Size\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=777,\n",
    "    stratify=y # Make sure to have the target column evenly distributed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1622512388346
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (2225,)\n",
      "X_train: (1780,)\n",
      "X_test: (445,)\n"
     ]
    }
   ],
   "source": [
    "# Check result of splitting\n",
    "print(\"X:\", X.shape)\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**NOTE**\n",
    "- **Currently, all the X's are in text format**\n",
    "- **We need to convert them into vectorial format instead**\n",
    "- **This will be done using TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Using TF-IDF for Vectorizing into Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1622512437716
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "- Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "- `TfidfVectorizer` is equivalent to `CountVectorizer` followed by `TfidfTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "```python\n",
    "class sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "    *,\n",
    "    input='content', \n",
    "    encoding='utf-8', \n",
    "    decode_error='strict', \n",
    "    strip_accents=None, \n",
    "    lowercase=True, \n",
    "    preprocessor=None, \n",
    "    tokenizer=None, \n",
    "    analyzer='word', \n",
    "    stop_words=None, \n",
    "    token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "    ngram_range=(1, 1), \n",
    "    max_df=1.0, \n",
    "    min_df=1, \n",
    "    max_features=None, \n",
    "    vocabulary=None, \n",
    "    binary=False, \n",
    "    dtype=<class 'numpy.float64'>, \n",
    "    norm='l2', \n",
    "    use_idf=True, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Define the hyperparameters of the TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1622512518010
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters for TF-IDF Vectorizer\n",
    "ngram_range = (1, 2)   # We are doing up to bigrams\n",
    "min_df = 10            # When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature\n",
    "max_df = 1.0           # When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words)\n",
    "# max_features = 300\n",
    "norm = \"l2\"\n",
    "sublinear_tf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1622512528168
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create a TF-IDF Vectorizer instance\n",
    "tfidf = TfidfVectorizer(\n",
    "    encoding=\"utf-8\",\n",
    "    ngram_range=ngram_range,\n",
    "    stop_words=None, # We already cleaned the text earlier in pre-processing\n",
    "    lowercase=False, # We already cleaned the text earlier in pre-processing\n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    norm=norm,\n",
    "    sublinear_tf=sublinear_tf\n",
    ")\n",
    "\n",
    "# Store the vectorized features and labels of the training and testing data\n",
    "# We can pass these to various ML algorithms later for comparing classification performance\n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "\n",
    "# Only transform on the test data\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1622512537408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_train: (1780, 5765)\n",
      "labels_train: (1780,)\n",
      "features_test: (445, 5765)\n",
      "labels_test: (445,)\n"
     ]
    }
   ],
   "source": [
    "# Checking where we are\n",
    "print(\"features_train:\", features_train.shape)\n",
    "print(\"labels_train:\", labels_train.shape)\n",
    "print(\"features_test:\", features_test.shape)\n",
    "print(\"labels_test:\", labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1622512546447
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vectorized Features for Training:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "--- Target Labels:\n",
      "709     1\n",
      "1374    3\n",
      "2016    4\n",
      "704     1\n",
      "260     0\n",
      "1709    3\n",
      "2162    4\n",
      "793     1\n",
      "56      0\n",
      "1342    3\n",
      "2079    4\n",
      "2013    4\n",
      "826     1\n",
      "1857    4\n",
      "139     1\n",
      "1727    3\n",
      "329     0\n",
      "1323    2\n",
      "686     1\n",
      "1793    3\n",
      "643     1\n",
      "1992    4\n",
      "1903    4\n",
      "844     1\n",
      "1914    4\n",
      "781     1\n",
      "1890    4\n",
      "2189    4\n",
      "368     0\n",
      "642     1\n",
      "1231    3\n",
      "1980    4\n",
      "1911    4\n",
      "2042    4\n",
      "2173    4\n",
      "1505    3\n",
      "836     1\n",
      "488     0\n",
      "787     1\n",
      "791     1\n",
      "1366    3\n",
      "1215    2\n",
      "233     0\n",
      "1414    3\n",
      "142     0\n",
      "834     1\n",
      "1332    2\n",
      "1735    3\n",
      "1961    4\n",
      "215     0\n",
      "1532    3\n",
      "1476    3\n",
      "2208    4\n",
      "1378    3\n",
      "68      0\n",
      "1781    3\n",
      "145     0\n",
      "2095    4\n",
      "1831    4\n",
      "255     0\n",
      "1481    3\n",
      "2207    4\n",
      "185     0\n",
      "1240    2\n",
      "2018    4\n",
      "83      0\n",
      "2144    4\n",
      "1477    3\n",
      "1712    3\n",
      "1027    2\n",
      "850     1\n",
      "1872    4\n",
      "113     0\n",
      "1399    3\n",
      "1670    3\n",
      "1492    3\n",
      "405     0\n",
      "1962    4\n",
      "1189    2\n",
      "1546    3\n",
      "213     0\n",
      "2082    4\n",
      "2011    4\n",
      "1282    2\n",
      "1460    3\n",
      "2134    4\n",
      "136     0\n",
      "888     1\n",
      "725     1\n",
      "1779    3\n",
      "974     2\n",
      "1731    3\n",
      "561     1\n",
      "1088    2\n",
      "102     0\n",
      "524     0\n",
      "1584    3\n",
      "515     0\n",
      "1433    3\n",
      "1084    2\n",
      "1091    2\n",
      "120     0\n",
      "1404    3\n",
      "206     0\n",
      "739     1\n",
      "349     0\n",
      "170     0\n",
      "2176    4\n",
      "957     2\n",
      "1835    4\n",
      "89      0\n",
      "1376    3\n",
      "1907    4\n",
      "1222    2\n",
      "1238    3\n",
      "1814    3\n",
      "1996    4\n",
      "2133    4\n",
      "2060    4\n",
      "1901    4\n",
      "362     0\n",
      "513     0\n",
      "1077    2\n",
      "1817    3\n",
      "2075    4\n",
      "641     1\n",
      "617     1\n",
      "499     0\n",
      "1263    2\n",
      "1926    4\n",
      "1218    2\n",
      "198     0\n",
      "757     1\n",
      "1054    2\n",
      "788     1\n",
      "107     0\n",
      "241     0\n",
      "1803    3\n",
      "1562    3\n",
      "1310    2\n",
      "673     1\n",
      "1976    4\n",
      "661     1\n",
      "1283    2\n",
      "1782    3\n",
      "1643    3\n",
      "2092    4\n",
      "876     1\n",
      "2038    4\n",
      "330     0\n",
      "1087    2\n",
      "1573    3\n",
      "2140    4\n",
      "301     0\n",
      "2020    4\n",
      "1136    2\n",
      "2197    4\n",
      "496     0\n",
      "220     0\n",
      "874     1\n",
      "1102    2\n",
      "1544    3\n",
      "689     1\n",
      "1986    4\n",
      "1571    3\n",
      "296     0\n",
      "1358    3\n",
      "653     1\n",
      "1248    2\n",
      "1822    3\n",
      "1347    3\n",
      "2089    4\n",
      "1513    3\n",
      "969     2\n",
      "1975    4\n",
      "399     0\n",
      "1531    3\n",
      "72      0\n",
      "849     1\n",
      "796     1\n",
      "149     0\n",
      "1335    2\n",
      "1036    2\n",
      "1994    4\n",
      "576     1\n",
      "1899    4\n",
      "823     1\n",
      "1484    3\n",
      "2120    4\n",
      "319     0\n",
      "1528    3\n",
      "799     1\n",
      "728     1\n",
      "1259    2\n",
      "1143    2\n",
      "179     0\n",
      "1520    3\n",
      "1350    3\n",
      "800     1\n",
      "2123    4\n",
      "121     0\n",
      "545     1\n",
      "2213    4\n",
      "87      0\n",
      "292     0\n",
      "1991    4\n",
      "745     1\n",
      "1698    3\n",
      "1928    4\n",
      "571     1\n",
      "126     0\n",
      "1113    2\n",
      "386     0\n",
      "497     0\n",
      "1122    2\n",
      "310     0\n",
      "58      0\n",
      "166     0\n",
      "1420    3\n",
      "1192    2\n",
      "968     2\n",
      "459     0\n",
      "2086    4\n",
      "1821    3\n",
      "2195    4\n",
      "1802    3\n",
      "1417    3\n",
      "1408    3\n",
      "771     1\n",
      "1668    3\n",
      "351     0\n",
      "525     1\n",
      "104     0\n",
      "1039    2\n",
      "851     1\n",
      "109     0\n",
      "2001    4\n",
      "1346    3\n",
      "1739    3\n",
      "366     0\n",
      "1707    3\n",
      "580     1\n",
      "2074    4\n",
      "2191    4\n",
      "1993    4\n",
      "1622    3\n",
      "1719    3\n",
      "1518    3\n",
      "195     0\n",
      "464     0\n",
      "1606    3\n",
      "27      0\n",
      "387     0\n",
      "1128    2\n",
      "971     2\n",
      "1393    3\n",
      "271     0\n",
      "712     1\n",
      "598     1\n",
      "935     2\n",
      "478     0\n",
      "944     2\n",
      "611     1\n",
      "168     0\n",
      "1086    2\n",
      "837     1\n",
      "677     1\n",
      "422     0\n",
      "1626    3\n",
      "934     2\n",
      "1663    3\n",
      "1594    3\n",
      "2111    4\n",
      "1786    3\n",
      "544     1\n",
      "662     1\n",
      "920     2\n",
      "1051    2\n",
      "596     1\n",
      "1645    3\n",
      "523     0\n",
      "1497    3\n",
      "843     1\n",
      "1613    3\n",
      "2190    4\n",
      "1765    3\n",
      "2032    4\n",
      "2186    4\n",
      "1494    3\n",
      "1116    2\n",
      "1538    3\n",
      "562     1\n",
      "13      0\n",
      "1876    4\n",
      "1211    2\n",
      "1325    2\n",
      "2100    4\n",
      "1299    2\n",
      "2028    4\n",
      "76      0\n",
      "1997    4\n",
      "964     2\n",
      "88      0\n",
      "755     1\n",
      "3       0\n",
      "1429    3\n",
      "2019    4\n",
      "1959    4\n",
      "2112    4\n",
      "2099    4\n",
      "692     1\n",
      "1789    3\n",
      "403     0\n",
      "450     0\n",
      "1641    3\n",
      "1933    4\n",
      "372     0\n",
      "407     0\n",
      "289     0\n",
      "1920    4\n",
      "1297    2\n",
      "1172    3\n",
      "1596    3\n",
      "585     1\n",
      "1014    2\n",
      "1588    3\n",
      "506     0\n",
      "1047    2\n",
      "1044    2\n",
      "602     1\n",
      "2215    4\n",
      "1167    2\n",
      "1053    2\n",
      "718     1\n",
      "1059    2\n",
      "672     1\n",
      "1578    3\n",
      "222     0\n",
      "640     1\n",
      "567     1\n",
      "84      0\n",
      "1660    3\n",
      "1147    2\n",
      "45      0\n",
      "607     1\n",
      "1416    3\n",
      "473     0\n",
      "40      0\n",
      "1542    3\n",
      "247     0\n",
      "2188    4\n",
      "655     1\n",
      "740     1\n",
      "334     0\n",
      "1873    4\n",
      "1776    3\n",
      "397     0\n",
      "154     0\n",
      "208     0\n",
      "1631    3\n",
      "315     3\n",
      "248     0\n",
      "592     1\n",
      "1145    2\n",
      "2098    4\n",
      "1865    4\n",
      "1811    3\n",
      "2008    4\n",
      "1295    2\n",
      "1867    4\n",
      "1080    2\n",
      "738     1\n",
      "977     2\n",
      "174     0\n",
      "998     2\n",
      "2124    4\n",
      "1442    3\n",
      "956     2\n",
      "2219    4\n",
      "2039    4\n",
      "1609    3\n",
      "992     2\n",
      "1061    2\n",
      "863     1\n",
      "2070    4\n",
      "1445    3\n",
      "1692    3\n",
      "522     1\n",
      "114     0\n",
      "1363    3\n",
      "1331    2\n",
      "769     1\n",
      "1853    4\n",
      "1885    4\n",
      "1804    3\n",
      "155     0\n",
      "1770    3\n",
      "1349    3\n",
      "577     1\n",
      "924     2\n",
      "294     3\n",
      "940     2\n",
      "1737    3\n",
      "981     2\n",
      "1257    2\n",
      "1120    2\n",
      "2148    4\n",
      "1337    2\n",
      "2085    4\n",
      "568     1\n",
      "1338    2\n",
      "1871    4\n",
      "308     0\n",
      "681     1\n",
      "682     1\n",
      "265     0\n",
      "212     0\n",
      "267     0\n",
      "156     1\n",
      "624     1\n",
      "1566    3\n",
      "119     0\n",
      "1963    4\n",
      "203     0\n",
      "480     0\n",
      "947     2\n",
      "970     2\n",
      "593     1\n",
      "1083    2\n",
      "1217    2\n",
      "1294    2\n",
      "1946    4\n",
      "2169    4\n",
      "1362    3\n",
      "148     0\n",
      "140     0\n",
      "1410    3\n",
      "29      0\n",
      "1856    4\n",
      "1419    3\n",
      "1945    4\n",
      "695     1\n",
      "1129    2\n",
      "1658    3\n",
      "664     1\n",
      "752     1\n",
      "1228    2\n",
      "1468    3\n",
      "557     1\n",
      "595     1\n",
      "1618    3\n",
      "881     3\n",
      "157     0\n",
      "1369    3\n",
      "597     1\n",
      "1078    2\n",
      "827     1\n",
      "1024    2\n",
      "137     0\n",
      "1960    4\n",
      "1290    2\n",
      "476     0\n",
      "958     2\n",
      "2137    4\n",
      "347     0\n",
      "1829    4\n",
      "1115    3\n",
      "75      0\n",
      "699     1\n",
      "563     1\n",
      "930     2\n",
      "2071    4\n",
      "1514    3\n",
      "2061    4\n",
      "418     0\n",
      "730     1\n",
      "630     1\n",
      "2183    4\n",
      "529     1\n",
      "1201    2\n",
      "903     1\n",
      "1430    3\n",
      "521     0\n",
      "1270    2\n",
      "894     1\n",
      "1450    3\n",
      "2110    4\n",
      "945     2\n",
      "1545    3\n",
      "1385    3\n",
      "277     0\n",
      "1395    3\n",
      "278     0\n",
      "634     1\n",
      "2181    4\n",
      "1913    4\n",
      "1139    2\n",
      "1733    3\n",
      "1838    4\n",
      "618     1\n",
      "414     0\n",
      "1504    3\n",
      "1458    3\n",
      "69      0\n",
      "1874    4\n",
      "67      0\n",
      "70      0\n",
      "2041    4\n",
      "1241    2\n",
      "564     1\n",
      "1232    2\n",
      "1936    4\n",
      "1746    3\n",
      "514     0\n",
      "1258    2\n",
      "1305    2\n",
      "2193    4\n",
      "8       0\n",
      "1927    4\n",
      "2171    4\n",
      "49      0\n",
      "1133    2\n",
      "2104    4\n",
      "1710    3\n",
      "1341    3\n",
      "1530    3\n",
      "722     1\n",
      "925     2\n",
      "1982    4\n",
      "457     0\n",
      "1123    2\n",
      "358     0\n",
      "1956    4\n",
      "1071    2\n",
      "1616    3\n",
      "1160    2\n",
      "1327    2\n",
      "1422    3\n",
      "184     0\n",
      "2031    4\n",
      "1526    3\n",
      "118     0\n",
      "1826    4\n",
      "1567    3\n",
      "1661    3\n",
      "666     1\n",
      "1153    2\n",
      "502     0\n",
      "866     1\n",
      "658     1\n",
      "841     1\n",
      "1431    3\n",
      "1186    2\n",
      "207     1\n",
      "1757    3\n",
      "2129    4\n",
      "1995    4\n",
      "1536    3\n",
      "1058    2\n",
      "839     1\n",
      "2059    4\n",
      "93      0\n",
      "733     1\n",
      "20      0\n",
      "1938    4\n",
      "1098    2\n",
      "448     0\n",
      "1       0\n",
      "1563    3\n",
      "172     0\n",
      "1860    4\n",
      "556     1\n",
      "797     1\n",
      "1713    3\n",
      "191     0\n",
      "240     0\n",
      "599     1\n",
      "1379    3\n",
      "359     0\n",
      "2043    4\n",
      "2078    4\n",
      "632     1\n",
      "555     1\n",
      "383     0\n",
      "1236    2\n",
      "526     1\n",
      "106     0\n",
      "2151    4\n",
      "451     0\n",
      "1948    4\n",
      "491     0\n",
      "587     1\n",
      "504     0\n",
      "2022    4\n",
      "2081    4\n",
      "1353    3\n",
      "1925    4\n",
      "2009    4\n",
      "178     0\n",
      "1234    2\n",
      "360     0\n",
      "468     0\n",
      "1026    2\n",
      "367     0\n",
      "1734    3\n",
      "2       0\n",
      "1082    2\n",
      "283     0\n",
      "652     1\n",
      "1989    4\n",
      "1066    2\n",
      "1370    3\n",
      "12      0\n",
      "41      0\n",
      "406     0\n",
      "1930    4\n",
      "1582    3\n",
      "295     0\n",
      "960     2\n",
      "1555    3\n",
      "1730    3\n",
      "1965    4\n",
      "262     0\n",
      "1085    2\n",
      "2210    4\n",
      "535     1\n",
      "1169    2\n",
      "1001    2\n",
      "541     1\n",
      "768     1\n",
      "2021    4\n",
      "1966    4\n",
      "1074    2\n",
      "1119    2\n",
      "1140    2\n",
      "258     0\n",
      "1922    4\n",
      "554     1\n",
      "2073    4\n",
      "167     0\n",
      "1816    3\n",
      "325     0\n",
      "1601    3\n",
      "1239    2\n",
      "912     2\n",
      "1747    3\n",
      "1832    4\n",
      "86      0\n",
      "1866    4\n",
      "955     2\n",
      "910     2\n",
      "932     2\n",
      "505     0\n",
      "1699    3\n",
      "1987    4\n",
      "425     0\n",
      "1939    4\n",
      "1894    4\n",
      "906     1\n",
      "1314    2\n",
      "744     1\n",
      "762     1\n",
      "615     1\n",
      "424     0\n",
      "763     1\n",
      "327     0\n",
      "2017    4\n",
      "1696    3\n",
      "1973    4\n",
      "1434    3\n",
      "472     0\n",
      "1842    4\n",
      "1207    2\n",
      "1163    2\n",
      "667     1\n",
      "1293    2\n",
      "1394    3\n",
      "1868    4\n",
      "890     1\n",
      "1289    2\n",
      "857     1\n",
      "1214    2\n",
      "305     0\n",
      "798     1\n",
      "1612    3\n",
      "548     1\n",
      "2220    4\n",
      "684     1\n",
      "500     0\n",
      "579     1\n",
      "1485    3\n",
      "2003    4\n",
      "1653    3\n",
      "737     1\n",
      "100     0\n",
      "2088    4\n",
      "883     1\n",
      "2024    4\n",
      "2002    4\n",
      "2057    4\n",
      "1882    4\n",
      "393     0\n",
      "1049    2\n",
      "1164    2\n",
      "1603    3\n",
      "1849    4\n",
      "219     0\n",
      "1836    4\n",
      "1022    2\n",
      "1743    3\n",
      "877     1\n",
      "249     0\n",
      "736     1\n",
      "1515    3\n",
      "441     0\n",
      "1210    2\n",
      "1787    3\n",
      "530     1\n",
      "1801    3\n",
      "707     1\n",
      "2131    4\n",
      "706     1\n",
      "5       0\n",
      "1005    2\n",
      "373     0\n",
      "1629    3\n",
      "21      0\n",
      "438     0\n",
      "1177    2\n",
      "647     1\n",
      "1686    3\n",
      "885     1\n",
      "687     1\n",
      "318     0\n",
      "698     1\n",
      "613     1\n",
      "854     1\n",
      "1685    3\n",
      "1155    2\n",
      "1855    4\n",
      "659     1\n",
      "1858    4\n",
      "2093    4\n",
      "73      0\n",
      "1179    2\n",
      "1893    4\n",
      "1216    2\n",
      "1020    2\n",
      "1806    3\n",
      "1516    3\n",
      "1465    3\n",
      "966     2\n",
      "926     2\n",
      "1794    3\n",
      "527     1\n",
      "186     0\n",
      "831     1\n",
      "1898    4\n",
      "921     2\n",
      "1386    3\n",
      "1171    2\n",
      "427     0\n",
      "2205    4\n",
      "1199    2\n",
      "551     1\n",
      "818     1\n",
      "1221    2\n",
      "1256    2\n",
      "24      0\n",
      "657     1\n",
      "1375    3\n",
      "2113    4\n",
      "1203    2\n",
      "1844    4\n",
      "1908    4\n",
      "676     1\n",
      "2096    4\n",
      "1041    2\n",
      "371     0\n",
      "199     0\n",
      "1678    3\n",
      "726     1\n",
      "1796    3\n",
      "1568    3\n",
      "1249    2\n",
      "453     0\n",
      "1266    2\n",
      "627     1\n",
      "54      0\n",
      "333     0\n",
      "1595    3\n",
      "1274    2\n",
      "105     0\n",
      "343     0\n",
      "648     1\n",
      "639     1\n",
      "1954    4\n",
      "1738    3\n",
      "216     0\n",
      "356     0\n",
      "915     2\n",
      "1904    4\n",
      "1581    3\n",
      "1004    2\n",
      "1624    3\n",
      "560     1\n",
      "264     0\n",
      "1045    2\n",
      "1302    2\n",
      "1837    4\n",
      "1112    2\n",
      "2064    4\n",
      "445     0\n",
      "1512    3\n",
      "2198    4\n",
      "928     2\n",
      "644     1\n",
      "2136    4\n",
      "1923    4\n",
      "979     2\n",
      "1943    4\n",
      "994     2\n",
      "553     1\n",
      "1436    3\n",
      "784     1\n",
      "501     0\n",
      "1030    2\n",
      "443     0\n",
      "1276    2\n",
      "1296    2\n",
      "162     0\n",
      "455     0\n",
      "62      0\n",
      "1880    4\n",
      "1681    3\n",
      "218     3\n",
      "227     0\n",
      "2117    4\n",
      "471     0\n",
      "1593    3\n",
      "1021    2\n",
      "536     1\n",
      "224     0\n",
      "735     1\n",
      "1917    4\n",
      "1111    2\n",
      "1714    3\n",
      "1753    3\n",
      "1910    4\n",
      "2047    4\n",
      "1586    3\n",
      "999     2\n",
      "720     1\n",
      "1333    2\n",
      "1543    3\n",
      "1610    3\n",
      "864     1\n",
      "590     1\n",
      "901     1\n",
      "1383    3\n",
      "1650    3\n",
      "606     1\n",
      "1708    3\n",
      "1974    4\n",
      "503     0\n",
      "1655    3\n",
      "2077    4\n",
      "886     1\n",
      "1724    3\n",
      "1680    3\n",
      "908     3\n",
      "2130    4\n",
      "317     0\n",
      "2161    4\n",
      "1019    2\n",
      "1340    2\n",
      "299     0\n",
      "1506    3\n",
      "201     0\n",
      "679     1\n",
      "2052    4\n",
      "1418    3\n",
      "47      0\n",
      "1471    3\n",
      "1764    3\n",
      "229     0\n",
      "1262    2\n",
      "1502    3\n",
      "1759    3\n",
      "512     0\n",
      "395     0\n",
      "2214    4\n",
      "1453    3\n",
      "853     1\n",
      "1093    2\n",
      "533     1\n",
      "1742    3\n",
      "2165    4\n",
      "2158    4\n",
      "1687    3\n",
      "2062    4\n",
      "303     0\n",
      "2026    4\n",
      "808     1\n",
      "777     1\n",
      "538     1\n",
      "1339    2\n",
      "1736    3\n",
      "1491    3\n",
      "869     1\n",
      "1953    4\n",
      "703     1\n",
      "494     0\n",
      "419     0\n",
      "1503    3\n",
      "842     1\n",
      "268     0\n",
      "2200    4\n",
      "1328    2\n",
      "382     0\n",
      "2126    4\n",
      "1951    4\n",
      "342     0\n",
      "1096    2\n",
      "2196    4\n",
      "670     1\n",
      "146     0\n",
      "188     0\n",
      "1912    4\n",
      "1805    3\n",
      "609     3\n",
      "122     0\n",
      "1607    3\n",
      "1565    3\n",
      "420     0\n",
      "1628    3\n",
      "132     0\n",
      "973     2\n",
      "1792    3\n",
      "2155    4\n",
      "1881    4\n",
      "324     0\n",
      "1159    2\n",
      "727     1\n",
      "972     2\n",
      "1246    2\n",
      "245     0\n",
      "1285    3\n",
      "435     0\n",
      "483     0\n",
      "2063    4\n",
      "1448    3\n",
      "253     0\n",
      "1919    4\n",
      "1955    4\n",
      "316     0\n",
      "10      0\n",
      "1423    3\n",
      "1522    3\n",
      "1788    3\n",
      "1682    3\n",
      "463     0\n",
      "1242    2\n",
      "693     1\n",
      "650     1\n",
      "489     0\n",
      "1322    2\n",
      "1243    2\n",
      "111     0\n",
      "1583    3\n",
      "1671    3\n",
      "1540    3\n",
      "674     1\n",
      "1181    2\n",
      "1372    3\n",
      "43      0\n",
      "77      0\n",
      "461     0\n",
      "1467    3\n",
      "272     3\n",
      "1064    2\n",
      "1070    2\n",
      "1268    2\n",
      "1251    3\n",
      "780     1\n",
      "2152    4\n",
      "1846    4\n",
      "300     0\n",
      "1287    2\n",
      "889     1\n",
      "1754    3\n",
      "939     2\n",
      "913     2\n",
      "63      0\n",
      "1165    2\n",
      "55      0\n",
      "1541    3\n",
      "26      0\n",
      "569     1\n",
      "1361    3\n",
      "1950    4\n",
      "276     0\n",
      "1130    2\n",
      "678     1\n",
      "537     1\n",
      "1094    2\n",
      "2182    4\n",
      "481     0\n",
      "1679    3\n",
      "209     0\n",
      "1073    2\n",
      "346     0\n",
      "812     1\n",
      "1368    3\n",
      "39      0\n",
      "980     2\n",
      "1892    4\n",
      "1300    2\n",
      "860     1\n",
      "896     1\n",
      "1398    3\n",
      "1090    2\n",
      "454     0\n",
      "1230    2\n",
      "663     1\n",
      "287     0\n",
      "605     1\n",
      "1783    3\n",
      "433     0\n",
      "1673    3\n",
      "1647    3\n",
      "312     0\n",
      "158     0\n",
      "409     0\n",
      "697     1\n",
      "2202    4\n",
      "1461    3\n",
      "235     0\n",
      "1840    4\n",
      "400     0\n",
      "996     2\n",
      "510     0\n",
      "995     2\n",
      "462     0\n",
      "710     1\n",
      "2146    4\n",
      "434     0\n",
      "2135    4\n",
      "231     0\n",
      "221     0\n",
      "22      0\n",
      "410     0\n",
      "385     0\n",
      "36      0\n",
      "2116    4\n",
      "2000    4\n",
      "1065    2\n",
      "1615    3\n",
      "452     0\n",
      "1559    3\n",
      "1553    3\n",
      "214     0\n",
      "2040    4\n",
      "2184    4\n",
      "801     1\n",
      "1198    2\n",
      "306     0\n",
      "152     0\n",
      "396     0\n",
      "11      0\n",
      "1012    2\n",
      "440     0\n",
      "2154    4\n",
      "550     1\n",
      "2044    4\n",
      "1250    2\n",
      "1202    2\n",
      "1852    4\n",
      "1016    2\n",
      "2168    4\n",
      "449     0\n",
      "1117    2\n",
      "1144    2\n",
      "835     1\n",
      "98      0\n",
      "1157    2\n",
      "1191    2\n",
      "1810    3\n",
      "2209    4\n",
      "1288    2\n",
      "1828    4\n",
      "621     1\n",
      "446     0\n",
      "902     1\n",
      "1219    2\n",
      "1740    3\n",
      "391     0\n",
      "1556    3\n",
      "1132    2\n",
      "753     1\n",
      "321     0\n",
      "1367    3\n",
      "975     2\n",
      "636     3\n",
      "2199    4\n",
      "751     1\n",
      "1298    2\n",
      "829     1\n",
      "1883    4\n",
      "1533    3\n",
      "1052    2\n",
      "1599    3\n",
      "1316    2\n",
      "337     0\n",
      "1443    3\n",
      "59      0\n",
      "1435    3\n",
      "1918    4\n",
      "767     1\n",
      "2094    4\n",
      "1011    2\n",
      "1455    3\n",
      "1101    2\n",
      "1176    2\n",
      "1768    3\n",
      "444     0\n",
      "700     1\n",
      "1902    4\n",
      "1457    3\n",
      "181     3\n",
      "123     0\n",
      "1208    2\n",
      "2083    4\n",
      "1100    2\n",
      "1861    4\n",
      "570     1\n",
      "1589    3\n",
      "1854    4\n",
      "2170    4\n",
      "887     1\n",
      "431     0\n",
      "2153    4\n",
      "270     0\n",
      "2166    4\n",
      "635     1\n",
      "1226    2\n",
      "982     2\n",
      "1126    2\n",
      "1635    3\n",
      "1018    2\n",
      "2216    4\n",
      "1758    3\n",
      "1957    4\n",
      "470     0\n",
      "408     0\n",
      "1495    3\n",
      "1990    4\n",
      "1909    4\n",
      "288     0\n",
      "291     0\n",
      "1384    3\n",
      "855     1\n",
      "1630    3\n",
      "990     2\n",
      "256     0\n",
      "285     0\n",
      "714     1\n",
      "14      0\n",
      "133     0\n",
      "713     1\n",
      "1889    4\n",
      "42      0\n",
      "1043    2\n",
      "511     0\n",
      "721     1\n",
      "1691    3\n",
      "1970    4\n",
      "1286    2\n",
      "1421    3\n",
      "1089    2\n",
      "1106    2\n",
      "1377    3\n",
      "2010    4\n",
      "764     1\n",
      "2103    4\n",
      "436     0\n",
      "821     1\n",
      "1791    3\n",
      "1397    3\n",
      "175     0\n",
      "251     0\n",
      "1149    2\n",
      "1146    2\n",
      "1235    2\n",
      "1121    2\n",
      "668     1\n",
      "466     0\n",
      "1247    2\n",
      "559     1\n",
      "180     0\n",
      "1312    2\n",
      "750     1\n",
      "2101    4\n",
      "1715    3\n",
      "2157    4\n",
      "2156    4\n",
      "2087    4\n",
      "1284    2\n",
      "2091    4\n",
      "269     0\n",
      "1633    3\n",
      "1197    2\n",
      "1972    4\n",
      "937     2\n",
      "1638    3\n",
      "1623    3\n",
      "131     0\n",
      "845     1\n",
      "2178    4\n",
      "429     0\n",
      "1863    4\n",
      "19      0\n",
      "2194    4\n",
      "1627    3\n",
      "1473    3\n",
      "1947    4\n",
      "1751    3\n",
      "1015    2\n",
      "18      0\n",
      "442     0\n",
      "1843    4\n",
      "1313    2\n",
      "474     0\n",
      "33      0\n",
      "1224    2\n",
      "1744    3\n",
      "1646    3\n",
      "1729    3\n",
      "1427    3\n",
      "1887    4\n",
      "819     1\n",
      "1391    3\n",
      "1056    2\n",
      "1940    4\n",
      "783     1\n",
      "815     1\n",
      "164     3\n",
      "225     0\n",
      "1763    3\n",
      "82      0\n",
      "357     0\n",
      "573     1\n",
      "1508    3\n",
      "1726    3\n",
      "1756    3\n",
      "916     2\n",
      "742     1\n",
      "1447    3\n",
      "1978    4\n",
      "1934    4\n",
      "897     3\n",
      "1958    4\n",
      "2187    4\n",
      "1695    3\n",
      "250     0\n",
      "147     0\n",
      "298     0\n",
      "997     2\n",
      "1401    3\n",
      "811     1\n",
      "1029    2\n",
      "1640    3\n",
      "1233    2\n",
      "716     1\n",
      "575     1\n",
      "1932    4\n",
      "717     1\n",
      "187     1\n",
      "1194    2\n",
      "583     1\n",
      "1307    2\n",
      "293     3\n",
      "99      0\n",
      "477     0\n",
      "2138    4\n",
      "1684    3\n",
      "1326    2\n",
      "1142    2\n",
      "929     2\n",
      "1482    3\n",
      "951     2\n",
      "51      0\n",
      "814     1\n",
      "2222    4\n",
      "1462    3\n",
      "376     0\n",
      "1634    3\n",
      "1114    2\n",
      "1690    3\n",
      "1683    3\n",
      "2115    4\n",
      "1833    4\n",
      "465     0\n",
      "242     0\n",
      "790     1\n",
      "223     0\n",
      "1600    3\n",
      "991     2\n",
      "2053    4\n",
      "1261    2\n",
      "159     0\n",
      "2149    4\n",
      "1387    3\n",
      "1356    3\n",
      "1412    3\n",
      "171     0\n",
      "1025    2\n",
      "1632    3\n",
      "2150    4\n",
      "161     0\n",
      "1550    3\n",
      "1184    2\n",
      "731     1\n",
      "1206    2\n",
      "1644    3\n",
      "485     0\n",
      "786     1\n",
      "2145    4\n",
      "948     2\n",
      "952     2\n",
      "1772    3\n",
      "1137    2\n",
      "961     2\n",
      "1317    2\n",
      "1003    2\n",
      "820     1\n",
      "1611    3\n",
      "1033    2\n",
      "228     0\n",
      "404     0\n",
      "482     0\n",
      "415     0\n",
      "1721    3\n",
      "1403    3\n",
      "486     0\n",
      "1452    3\n",
      "490     0\n",
      "2185    4\n",
      "1585    3\n",
      "1941    4\n",
      "552     1\n",
      "1771    3\n",
      "2121    4\n",
      "1501    3\n",
      "2164    4\n",
      "1480    3\n",
      "177     0\n",
      "412     0\n",
      "1900    4\n",
      "353     0\n",
      "1304    2\n",
      "1255    2\n",
      "772     1\n",
      "141     0\n",
      "1264    2\n",
      "1830    4\n",
      "57      0\n",
      "81      0\n",
      "1674    3\n",
      "1725    3\n",
      "734     1\n",
      "719     1\n",
      "574     1\n",
      "236     0\n",
      "770     1\n",
      "1057    2\n",
      "211     0\n",
      "804     1\n",
      "779     1\n",
      "402     0\n",
      "1774    3\n",
      "1472    3\n",
      "6       0\n",
      "96      0\n",
      "417     0\n",
      "729     1\n",
      "620     1\n",
      "683     1\n",
      "1689    3\n",
      "1048    2\n",
      "279     0\n",
      "1850    4\n",
      "1741    3\n",
      "46      0\n",
      "498     0\n",
      "322     3\n",
      "588     1\n",
      "1354    3\n",
      "25      0\n",
      "378     0\n",
      "135     0\n",
      "600     1\n",
      "1245    3\n",
      "2004    4\n",
      "475     0\n",
      "691     1\n",
      "1183    2\n",
      "1475    3\n",
      "1127    2\n",
      "2127    4\n",
      "313     0\n",
      "380     0\n",
      "1525    3\n",
      "1438    3\n",
      "2036    4\n",
      "1572    3\n",
      "1308    2\n",
      "1193    2\n",
      "1574    3\n",
      "1411    3\n",
      "384     0\n",
      "7       0\n",
      "1466    3\n",
      "1154    2\n",
      "1359    3\n",
      "1097    2\n",
      "589     1\n",
      "748     1\n",
      "1223    2\n",
      "987     2\n",
      "1498    3\n",
      "1834    4\n",
      "1424    3\n",
      "492     0\n",
      "846     1\n",
      "933     2\n",
      "1320    2\n",
      "311     0\n",
      "200     0\n",
      "817     1\n",
      "1253    2\n",
      "1141    2\n",
      "656     1\n",
      "540     1\n",
      "1937    4\n",
      "1984    4\n",
      "66      0\n",
      "1437    3\n",
      "1621    3\n",
      "833     1\n",
      "1170    2\n",
      "1755    3\n",
      "388     0\n",
      "517     0\n",
      "183     0\n",
      "1539    3\n",
      "423     0\n",
      "1706    3\n",
      "671     1\n",
      "1446    3\n",
      "1614    3\n",
      "1134    2\n",
      "35      0\n",
      "232     0\n",
      "1035    2\n",
      "30      0\n",
      "1229    2\n",
      "724     1\n",
      "2212    4\n",
      "1648    3\n",
      "680     1\n",
      "1924    4\n",
      "1597    3\n",
      "64      0\n",
      "2192    4\n",
      "1483    3\n",
      "875     1\n",
      "1008    2\n",
      "2102    4\n",
      "364     0\n",
      "927     2\n",
      "1381    3\n",
      "2029    4\n",
      "907     1\n",
      "79      0\n",
      "1213    2\n",
      "610     1\n",
      "1760    3\n",
      "1131    2\n",
      "1558    3\n",
      "1728    3\n",
      "1905    4\n",
      "898     1\n",
      "856     1\n",
      "331     0\n",
      "134     0\n",
      "633     1\n",
      "381     0\n",
      "192     0\n",
      "101     0\n",
      "1402    3\n",
      "1108    2\n",
      "266     0\n",
      "1319    2\n",
      "1716    3\n",
      "1931    4\n",
      "1464    3\n",
      "2046    4\n",
      "456     0\n",
      "758     1\n",
      "1537    3\n",
      "1929    4\n",
      "1104    2\n",
      "623     1\n",
      "1330    2\n",
      "638     1\n",
      "1188    2\n",
      "2037    4\n",
      "1723    3\n",
      "715     1\n",
      "205     0\n",
      "2048    4\n",
      "165     0\n",
      "1063    2\n",
      "1023    2\n",
      "1800    3\n",
      "1488    3\n",
      "1591    3\n",
      "1038    2\n",
      "2050    4\n",
      "696     1\n",
      "163     0\n",
      "892     1\n",
      "508     0\n",
      "2180    4\n",
      "182     0\n",
      "1819    3\n",
      "1150    2\n",
      "2177    4\n",
      "1785    3\n",
      "1454    3\n",
      "1569    3\n",
      "1138    2\n",
      "1507    3\n",
      "1315    2\n",
      "1006    2\n",
      "2058    4\n",
      "1277    2\n",
      "2147    4\n",
      "967     2\n",
      "813     1\n",
      "628     1\n",
      "2141    4\n",
      "594     1\n",
      "2143    4\n",
      "649     1\n",
      "263     0\n",
      "1031    2\n",
      "124     0\n",
      "1703    3\n",
      "458     0\n",
      "983     2\n",
      "1161    2\n",
      "1667    3\n",
      "895     1\n",
      "539     1\n",
      "259     0\n",
      "348     0\n",
      "1000    2\n",
      "1701    3\n",
      "150     0\n",
      "1156    2\n",
      "1318    2\n",
      "702     1\n",
      "1432    3\n",
      "2109    4\n",
      "918     2\n",
      "90      0\n",
      "493     0\n",
      "1013    2\n",
      "1007    2\n",
      "1717    3\n",
      "756     1\n",
      "1968    4\n",
      "151     1\n",
      "785     1\n",
      "2030    4\n",
      "1579    3\n",
      "169     1\n",
      "665     1\n",
      "1105    2\n",
      "694     1\n",
      "1042    2\n",
      "1152    2\n",
      "1560    3\n",
      "439     0\n",
      "484     0\n",
      "1440    3\n",
      "1451    3\n",
      "1178    2\n",
      "1040    2\n",
      "1637    3\n",
      "1839    4\n",
      "426     0\n",
      "1390    3\n",
      "94      0\n",
      "1935    4\n",
      "350     0\n",
      "1527    3\n",
      "803     1\n",
      "942     2\n",
      "1265    2\n",
      "1081    2\n",
      "775     1\n",
      "946     2\n",
      "1205    2\n",
      "873     1\n",
      "1554    3\n",
      "1869    4\n",
      "1651    3\n",
      "48      0\n",
      "586     1\n",
      "1677    3\n",
      "112     0\n",
      "1773    3\n",
      "1564    3\n",
      "1364    3\n",
      "1099    2\n",
      "1357    3\n",
      "341     0\n",
      "2160    4\n",
      "1345    3\n",
      "1700    3\n",
      "905     1\n",
      "1841    4\n",
      "518     0\n",
      "1382    3\n",
      "732     1\n",
      "239     0\n",
      "1463    3\n",
      "1809    3\n",
      "1797    3\n",
      "865     1\n",
      "688     1\n",
      "1694    3\n",
      "309     0\n",
      "1878    4\n",
      "284     0\n",
      "432     0\n",
      "1204    2\n",
      "1225    3\n",
      "1604    3\n",
      "2023    4\n",
      "1547    3\n",
      "1884    4\n",
      "2005    4\n",
      "1827    4\n",
      "1413    3\n",
      "1587    3\n",
      "1769    3\n",
      "1820    3\n",
      "572     1\n",
      "776     1\n",
      "2114    4\n",
      "616     1\n",
      "1212    3\n",
      "1032    2\n",
      "129     0\n",
      "9       0\n",
      "1577    3\n",
      "363     0\n",
      "377     0\n",
      "394     0\n",
      "622     1\n",
      "1396    3\n",
      "52      0\n",
      "2107    4\n",
      "257     0\n",
      "1704    3\n",
      "467     0\n",
      "1720    3\n",
      "1608    3\n",
      "2006    4\n",
      "1076    2\n",
      "2056    4\n",
      "723     1\n",
      "654     1\n",
      "204     0\n",
      "1659    3\n",
      "243     0\n",
      "806     1\n",
      "1166    2\n",
      "1675    3\n",
      "297     0\n",
      "1118    2\n",
      "2072    4\n",
      "144     0\n",
      "1444    3\n",
      "509     0\n",
      "302     0\n",
      "1636    3\n",
      "985     2\n",
      "1195    3\n",
      "631     1\n",
      "1441    3\n",
      "1886    4\n",
      "637     1\n",
      "2025    4\n",
      "2174    4\n",
      "345     0\n",
      "1983    4\n",
      "401     0\n",
      "2122    4\n",
      "1329    2\n",
      "173     0\n",
      "252     0\n",
      "61      0\n",
      "1348    3\n",
      "861     1\n",
      "261     0\n",
      "936     3\n",
      "660     1\n",
      "778     1\n",
      "619     1\n",
      "872     1\n",
      "782     1\n",
      "1664    3\n",
      "520     0\n",
      "15      0\n",
      "1592    3\n",
      "868     1\n",
      "1549    3\n",
      "1625    3\n",
      "848     1\n",
      "962     2\n",
      "1845    4\n",
      "1220    2\n",
      "1575    3\n",
      "1870    4\n",
      "1778    3\n",
      "601     1\n",
      "428     0\n",
      "430     0\n",
      "1576    3\n",
      "963     2\n",
      "1271    2\n",
      "1469    3\n",
      "1095    2\n",
      "153     0\n",
      "824     1\n",
      "1135    3\n",
      "1426    3\n",
      "280     0\n",
      "1551    3\n",
      "531     1\n",
      "1509    3\n",
      "1534    3\n",
      "110     0\n",
      "1652    3\n",
      "705     1\n",
      "993     2\n",
      "1711    3\n",
      "1405    3\n",
      "2159    4\n",
      "1237    3\n",
      "743     1\n",
      "765     1\n",
      "2034    4\n",
      "1896    4\n",
      "1519    3\n",
      "1067    2\n",
      "1037    2\n",
      "1702    3\n",
      "794     1\n",
      "774     1\n",
      "690     1\n",
      "217     0\n",
      "1279    2\n",
      "1979    4\n",
      "97      0\n",
      "Name: category_target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking what they look like\n",
    "print(\"--- Vectorized Features for Training:\")\n",
    "print(features_train)\n",
    "print(\"--- Target Labels:\")\n",
    "print(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**We now have our sparse matrices ready to being used for Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Using Random Forest Model (RF) -- Out of the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_rf = RandomForestClassifier(random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=777,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_rf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 0, 3, 1, 0, 2, 1, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 3, 3, 2, 3, 1, 3,\n",
       "       3, 1, 4, 1, 4, 0, 4, 4, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 3, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 0, 0, 4,\n",
       "       2, 4, 3, 0, 2, 0, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 1, 3, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 3, 3, 0, 2, 0, 1, 1, 3, 4, 0, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 1, 4, 0, 4, 0, 0, 2, 0, 0, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 0, 4, 0, 3, 2, 0, 1, 1, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 4, 4, 3, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 2,\n",
       "       2, 3, 1, 3, 0, 3, 3, 3, 4, 1, 1, 0, 2, 0, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 3, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 0, 2, 2, 3, 3, 2, 2, 0, 2, 3, 2, 3, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 0, 1, 0, 1, 0, 0, 0, 4,\n",
       "       2, 3, 2, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       4, 0, 0, 0, 2, 0, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 1,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_rf.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483146067415731\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       102\n",
      "           1       0.99      0.94      0.96        77\n",
      "           2       0.96      0.95      0.96        84\n",
      "           3       0.91      0.99      0.95       102\n",
      "           4       1.00      0.84      0.91        80\n",
      "\n",
      "    accuracy                           0.95       445\n",
      "   macro avg       0.96      0.94      0.95       445\n",
      "weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Using Logistic Regression Model (LR) -- Out of the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_lr.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 0, 3, 1, 0, 2, 1, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 3, 3, 2, 3, 1, 3,\n",
       "       3, 1, 4, 1, 4, 0, 4, 4, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 3, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 2, 0, 4,\n",
       "       2, 4, 3, 0, 2, 0, 3, 2, 1, 2, 2, 2, 3, 0, 3, 3, 1, 4, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 1, 3, 0, 2, 0, 1, 1, 3, 4, 0, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 1, 4, 0, 4, 0, 0, 2, 0, 0, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 1, 4, 0, 3, 2, 0, 1, 1, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 2, 4, 4, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 2,\n",
       "       2, 2, 1, 3, 0, 4, 4, 3, 4, 1, 1, 0, 2, 0, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 3, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 4, 2, 2, 3, 3, 2, 2, 0, 2, 3, 1, 3, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 0, 2, 0, 1, 2, 2, 0, 4,\n",
       "       2, 3, 3, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       0, 0, 0, 0, 2, 4, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 1,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_lr.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       102\n",
      "           1       1.00      0.97      0.99        77\n",
      "           2       0.95      1.00      0.98        84\n",
      "           3       0.96      1.00      0.98       102\n",
      "           4       1.00      0.89      0.94        80\n",
      "\n",
      "    accuracy                           0.97       445\n",
      "   macro avg       0.98      0.97      0.97       445\n",
      "weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Using K-Nearest Neighbors Model (KNN) -- Out of the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_knn.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 4, 3, 1, 0, 2, 1, 0, 3, 4, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 3, 3, 2, 3, 1, 3,\n",
       "       3, 1, 4, 1, 4, 0, 4, 1, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 3, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 2, 0, 4,\n",
       "       2, 4, 3, 0, 2, 0, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 1, 4, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 1, 3, 0, 2, 0, 1, 1, 3, 4, 0, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 1, 4, 0, 4, 0, 0, 2, 0, 0, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 1, 4, 4, 3, 2, 0, 1, 1, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 2, 4, 4, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 4,\n",
       "       2, 2, 1, 3, 2, 4, 4, 3, 4, 1, 1, 0, 2, 0, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 4, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 4, 2, 2, 3, 3, 2, 2, 0, 2, 3, 1, 4, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 0, 0, 3, 3, 0, 4, 4, 3, 4, 2, 0, 4, 1, 1, 2, 2, 0, 4,\n",
       "       2, 3, 3, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       4, 0, 0, 0, 2, 3, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 1,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_knn.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9662921348314607\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       102\n",
      "           1       0.99      0.99      0.99        77\n",
      "           2       0.97      0.99      0.98        84\n",
      "           3       0.97      1.00      0.99       102\n",
      "           4       0.95      0.90      0.92        80\n",
      "\n",
      "    accuracy                           0.97       445\n",
      "   macro avg       0.97      0.97      0.97       445\n",
      "weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Using Simple Decision Tree Model (dt) -- Out of the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_dt.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 3, 3, 0, 2, 3, 3, 1, 3, 2, 2, 4, 2, 3, 0, 1, 4, 3, 3, 3,\n",
       "       4, 4, 3, 4, 0, 2, 1, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 0, 4, 1, 0, 0, 4, 2, 3, 3, 3, 2, 4, 4, 0, 4, 3, 3, 0, 2, 1, 3,\n",
       "       3, 1, 4, 1, 4, 4, 4, 4, 0, 3, 0, 2, 3, 2, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 4, 0, 4, 3, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 0, 2, 4, 4, 0, 3, 3, 3, 2, 2, 0, 3, 1, 3, 3, 0, 3, 4, 4,\n",
       "       2, 0, 3, 0, 1, 0, 3, 4, 1, 2, 2, 1, 3, 0, 3, 3, 1, 4, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 2, 0, 3, 0, 2, 0, 1, 1, 3, 4, 4, 2, 0, 3, 2, 0,\n",
       "       1, 0, 4, 0, 3, 1, 2, 1, 2, 0, 4, 0, 2, 2, 0, 2, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 4, 4, 2, 3, 2, 0, 1, 1, 4, 4, 0, 2, 3, 0, 3, 3, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 2, 4, 4, 2, 3, 3, 3, 3, 1, 2, 2, 0, 3, 0,\n",
       "       1, 1, 0, 0, 1, 4, 2, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 1,\n",
       "       2, 3, 3, 3, 3, 4, 4, 3, 4, 1, 1, 0, 2, 1, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 2, 4, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 3, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 0, 2, 3, 4, 1, 4, 0, 1, 4, 4, 3, 3, 1, 3, 0, 0, 1, 2, 3,\n",
       "       4, 4, 1, 2, 2, 1, 2, 1, 0, 2, 2, 4, 2, 1, 0, 4, 4, 3, 4, 2, 1, 0,\n",
       "       2, 2, 1, 3, 3, 0, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 0, 2, 0, 0, 1, 3,\n",
       "       2, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 2, 3, 0, 0, 2, 0, 1, 4,\n",
       "       2, 2, 0, 4, 0, 2, 0, 4, 4, 4, 4, 4, 0, 0, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       0, 4, 0, 0, 0, 4, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 0, 0, 2, 2, 1,\n",
       "       3, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_dt.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Decision Tree Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.797752808988764\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       102\n",
      "           1       0.90      0.74      0.81        77\n",
      "           2       0.71      0.79      0.75        84\n",
      "           3       0.88      0.90      0.89       102\n",
      "           4       0.79      0.79      0.79        80\n",
      "\n",
      "    accuracy                           0.80       445\n",
      "   macro avg       0.80      0.79      0.80       445\n",
      "weighted avg       0.80      0.80      0.80       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Using Gaussian Naive Bayes Model (gnb) -- Out of the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_gnb.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 0, 2, 1, 3, 3, 3,\n",
       "       1, 0, 3, 1, 0, 0, 1, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       4, 0, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 4, 3, 2, 3, 1, 3,\n",
       "       3, 4, 4, 1, 4, 0, 4, 4, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 1, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 4, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 2, 0, 4,\n",
       "       2, 4, 3, 2, 2, 0, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 1, 4, 2, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 1, 3, 0, 2, 0, 2, 1, 3, 4, 4, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 4, 4, 0, 4, 0, 0, 2, 0, 0, 0, 4, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 1, 4, 0, 3, 2, 0, 1, 2, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 2, 1, 3, 2, 4, 1, 2, 4, 4, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 2,\n",
       "       2, 0, 1, 3, 0, 4, 4, 3, 4, 1, 1, 0, 2, 0, 2, 0, 3, 0, 4, 4, 3, 4,\n",
       "       0, 0, 3, 2, 4, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 4, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 4, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 4, 2, 2, 3, 3, 2, 2, 0, 2, 3, 4, 4, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 2, 0, 4, 1, 0, 2, 4, 4,\n",
       "       2, 3, 2, 0, 2, 0, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       4, 2, 0, 0, 2, 4, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 4,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_gnb.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9213483146067416\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       102\n",
      "           1       0.98      0.83      0.90        77\n",
      "           2       0.86      0.93      0.89        84\n",
      "           3       1.00      0.99      1.00       102\n",
      "           4       0.85      0.93      0.89        80\n",
      "\n",
      "    accuracy                           0.92       445\n",
      "   macro avg       0.92      0.92      0.92       445\n",
      "weighted avg       0.93      0.92      0.92       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Classification With Hyper-Parameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Previously, our best score with Random Forest (Out-of-the-box) was 0.9483"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "gather": {
     "logged": 1622512239858
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1622512254261
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameters for the grid\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 10, 15, 20, 25, 30]\n",
    "min_samples_split = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "min_samples_leaf = [1, 5, 10, 15]\n",
    "\n",
    "# Finalize the params for GridSearchCV\n",
    "hyper_params = dict(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1622512279206
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with GridSearchCV: 3-folds CV\n",
    "model_rf = RandomForestClassifier(random_state=777)\n",
    "grid_cv_rf = GridSearchCV(\n",
    "    model_rf, \n",
    "    hyper_params, \n",
    "    cv=3, # 3-folds-CV\n",
    "    verbose=4,\n",
    "    n_jobs=-1 # Use all available cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1320 candidates, totalling 3960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   17.5s\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 61.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 75.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3960 out of 3960 | elapsed: 85.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit on the training set to get the best model\n",
    "best_rf = grid_cv_rf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 20,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest With Best Params From Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_rf_best = RandomForestClassifier(\n",
    "    random_state=777,\n",
    "    max_depth=30,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=20,\n",
    "    n_estimators=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=30, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=20,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=None, oob_score=False, random_state=777,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_rf_best.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 0, 3, 1, 0, 2, 1, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 3, 3, 2, 3, 1, 3,\n",
       "       3, 1, 4, 1, 4, 4, 4, 4, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 3, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 0, 0, 4,\n",
       "       2, 4, 3, 0, 2, 0, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 1, 4, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 3, 3, 0, 2, 0, 1, 1, 3, 4, 0, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 1, 4, 0, 4, 0, 0, 2, 0, 0, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 0, 4, 2, 3, 2, 0, 1, 1, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 4, 4, 3, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 4,\n",
       "       2, 3, 1, 3, 0, 3, 4, 3, 4, 1, 1, 0, 2, 0, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 3, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 0, 2, 2, 3, 3, 2, 2, 0, 2, 3, 2, 3, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 0, 0, 4, 0, 2, 0, 0, 4,\n",
       "       2, 3, 3, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       4, 0, 0, 0, 2, 0, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 1,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_rf_best.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest With Best Params From Grid Search Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9550561797752809\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       102\n",
      "           1       1.00      0.94      0.97        77\n",
      "           2       0.96      0.95      0.96        84\n",
      "           3       0.93      1.00      0.96       102\n",
      "           4       0.99      0.89      0.93        80\n",
      "\n",
      "    accuracy                           0.96       445\n",
      "   macro avg       0.96      0.95      0.95       445\n",
      "weighted avg       0.96      0.96      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our best score with Logistic Regression (Out-of-the-box) was 0.9730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the grid\n",
    "param_grid = {\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with GridSearchCV: 5-folds CV\n",
    "model_lr = LogisticRegression()\n",
    "grid_cv_lr = GridSearchCV(\n",
    "    model_lr, \n",
    "    param_grid, \n",
    "    cv=5, # 5-folds-CV\n",
    "    verbose=4,\n",
    "    n_jobs=-1 # Use all available cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   23.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit on the training set to get the best model\n",
    "best_lr = grid_cv_lr.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.7, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression With Best Params From GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_lr_best = LogisticRegression(C=0.7, penalty=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_lr_best.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 0, 3, 1, 0, 2, 1, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 3, 3, 2, 3, 1, 3,\n",
       "       3, 1, 4, 1, 4, 0, 4, 4, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 3, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 2, 0, 4,\n",
       "       2, 4, 3, 0, 2, 0, 3, 2, 1, 2, 2, 2, 3, 0, 3, 3, 1, 4, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 1, 3, 0, 2, 0, 1, 1, 3, 4, 0, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 1, 4, 0, 4, 0, 0, 2, 0, 0, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 1, 4, 0, 3, 2, 0, 1, 1, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 2, 4, 4, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 2,\n",
       "       2, 2, 1, 3, 0, 4, 4, 3, 4, 1, 1, 0, 2, 0, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 3, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 4, 2, 2, 3, 3, 2, 2, 0, 2, 3, 1, 3, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 0, 2, 0, 1, 2, 2, 0, 4,\n",
       "       2, 3, 3, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       0, 0, 0, 0, 2, 4, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 1,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_lr_best.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression With Best Params From Grid Search Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       102\n",
      "           1       1.00      0.97      0.99        77\n",
      "           2       0.95      1.00      0.98        84\n",
      "           3       0.96      1.00      0.98       102\n",
      "           4       1.00      0.89      0.94        80\n",
      "\n",
      "    accuracy                           0.97       445\n",
      "   macro avg       0.98      0.97      0.97       445\n",
      "weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our best score with K-Nearest Neighbors (Out-of-the-box) was 0.9663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the grid\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [2, 3, 4, 5, 6, 7],\n",
    "    \"p\": [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with GridSearchCV: 3-folds CV\n",
    "model_knn = KNeighborsClassifier()\n",
    "grid_cv_knn = GridSearchCV(\n",
    "    model_knn, \n",
    "    param_grid, \n",
    "    cv=3, # 3-folds-CV\n",
    "    verbose=4,\n",
    "    n_jobs=-1 # Use all available cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 15.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit on the training set to get the best model\n",
    "best_knn = grid_cv_knn.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7, 'p': 2}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using K-Nearest Neighbors With Best Params From GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_knn_best = KNeighborsClassifier(n_neighbors=7, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_knn_best.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 3, 0, 2, 3, 3, 1, 0, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 0, 3, 1, 0, 2, 1, 0, 3, 4, 1, 4, 0, 0, 0, 0, 3, 1, 2, 3, 4, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 3, 1, 3, 3, 0, 4, 0, 4, 3, 3, 2, 3, 1, 3,\n",
       "       3, 1, 4, 1, 4, 0, 4, 1, 0, 3, 1, 2, 3, 0, 3, 2, 4, 4, 2, 3, 3, 0,\n",
       "       0, 2, 4, 2, 3, 0, 4, 4, 3, 3, 1, 0, 3, 3, 3, 2, 4, 0, 0, 2, 2, 3,\n",
       "       4, 3, 0, 1, 2, 4, 4, 0, 3, 3, 3, 0, 2, 0, 3, 1, 3, 3, 1, 2, 0, 4,\n",
       "       2, 4, 3, 4, 2, 0, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 1, 4, 1, 0, 3, 2,\n",
       "       3, 2, 1, 3, 2, 2, 4, 1, 3, 0, 2, 0, 1, 1, 3, 4, 0, 2, 4, 3, 2, 0,\n",
       "       1, 0, 4, 4, 3, 1, 2, 1, 4, 0, 4, 0, 0, 2, 0, 0, 0, 1, 4, 0, 3, 4,\n",
       "       3, 0, 1, 1, 0, 4, 4, 0, 3, 2, 0, 1, 1, 4, 4, 0, 0, 3, 0, 3, 0, 2,\n",
       "       1, 0, 0, 1, 3, 2, 4, 1, 2, 4, 4, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2,\n",
       "       1, 1, 2, 0, 1, 4, 0, 3, 1, 2, 1, 1, 2, 2, 1, 3, 3, 3, 3, 2, 0, 4,\n",
       "       2, 2, 1, 3, 0, 4, 4, 3, 4, 1, 1, 0, 2, 0, 4, 0, 3, 0, 0, 4, 3, 4,\n",
       "       0, 0, 3, 2, 1, 0, 2, 1, 1, 2, 2, 2, 1, 4, 0, 0, 4, 3, 3, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 3, 4, 1, 4, 0, 1, 4, 4, 3, 3, 3, 3, 3, 0, 1, 2, 3,\n",
       "       4, 4, 1, 0, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 0, 4, 4, 3, 4, 1, 1, 2,\n",
       "       4, 2, 1, 3, 3, 4, 2, 2, 3, 3, 2, 2, 0, 2, 3, 1, 4, 2, 0, 0, 2, 3,\n",
       "       3, 0, 4, 2, 4, 0, 3, 3, 0, 4, 4, 3, 4, 2, 0, 4, 4, 1, 2, 2, 0, 4,\n",
       "       2, 3, 3, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 2, 0, 4, 0, 0, 0, 3, 0, 3,\n",
       "       4, 0, 0, 0, 2, 4, 4, 2, 2, 3, 0, 0, 1, 3, 3, 4, 3, 2, 0, 2, 3, 1,\n",
       "       1, 1, 2, 0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "labels_pred = model_knn_best.predict(features_test)\n",
    "display(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors With Best Params From Grid Search Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       102\n",
      "           1       0.99      0.97      0.98        77\n",
      "           2       0.98      0.99      0.98        84\n",
      "           3       0.98      1.00      0.99       102\n",
      "           4       0.94      0.93      0.93        80\n",
      "\n",
      "    accuracy                           0.97       445\n",
      "   macro avg       0.97      0.97      0.97       445\n",
      "weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Accuracy Scores on `test` data:\n",
    "\n",
    "- Random Forest -- No Tuning: 0.9483\n",
    "- Logistic Regression: 0.9730\n",
    "- K-Nearest Neighbors: 0.9663\n",
    "- Simple Decision Tree: 0.7978\n",
    "- Gaussian Naive Bayes: 0.9213\n",
    "- Random Forest -- GridSearchCV: 0.9551\n",
    "- Logistic Regression -- GridSearchCV: 0.9730\n",
    "- K-Nearest-Neighbors -- GridsearchCV: 0.9730"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
